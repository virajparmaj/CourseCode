{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Assignment 3 - [30 points]\n",
    "\n",
    "\n",
    "In this analysis, we will perform two case studies.\n",
    "\n",
    "\n",
    "\n",
    "## <u>Case Study 1</u>: Artificial Dataset Scaling Analysis\n",
    "Let's learn more about how data scaling choices might affect our cluster analysis results.\n",
    "\n",
    "In this case study we will first perform a cluster analysis on a two dimensional, artificial dataset (**dataset2.csv**) that has not been scaled. Then we will perform a cluster analysis on the scaled dataset.\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Hopkin's Statistic\n",
    "\n",
    "The `pyclustertend` package does not seem to be well maintained. You may encounter issues installing and using this package for newer versions of Python. You can use this function instead to calculate the Hopkin's statistic. Note that the only input into this function is just the dataframe of variables that you would like to determine clusterability.\n",
    "\n",
    "The $p$ value is already set to be the rule of thumb (10% of the number of observations in the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def hopkins_stat(X):\n",
    "    n, d = X.shape\n",
    "    p = int(0.1 * n) \n",
    "\n",
    "    # Nearest Neighbors Model\n",
    "    nbrs = NearestNeighbors(n_neighbors=2).fit(X)\n",
    "    \n",
    "    # Randomly selected sample points\n",
    "    rand_ind = np.random.choice(range(0, n), p, replace=False)\n",
    "    \n",
    "    # Compute u_dist and w_dist without using iloc\n",
    "    u_dist, _ = nbrs.kneighbors(np.random.uniform(np.min(X, axis=0), np.max(X, axis=0), (p, d)), 2)\n",
    "    w_dist, _ = nbrs.kneighbors(X[rand_ind], 2)  # Fix: Direct indexing instead of iloc\n",
    "\n",
    "    # Extract distances\n",
    "    u_dist = u_dist[:, 1]\n",
    "    w_dist = w_dist[:, 1]\n",
    "\n",
    "    # Compute Hopkins statistic\n",
    "    h_stat = np.sum(w_dist) / (np.sum(u_dist) + np.sum(w_dist))\n",
    "\n",
    "    return h_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### 1. Unscaled Dataset Analysis\n",
    "\n",
    "#### 1.1. Read dataset2.csv\n",
    "\n",
    "Read the dataset2.csv file into a dataframe. You can assume that there are no missing values in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset2.csv\")\n",
    "X = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.  Initial Plotting \n",
    "Plot this dataframe in a scatterplot. Just by looking at this scatterplot, do you think that this dataset is clusterable?\n",
    "\n",
    "**Hint: In this problem 1.2, don't modify the upper or lower bound limits of the plot window.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], s=25, alpha=0.6)\n",
    "plt.title(\"Scatter Plot of Dataset\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes the dataset is clusterable however the effectiveensity is debatable due to the lesser dense clusters with widely distributed points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.  Describing the Numerical Variales\n",
    "\n",
    "For each numerical variable in the dataframe, show the mean, standard deviation, minimum, Q1, median, Q3, and maxium value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = df.describe(percentiles=[0.25, 0.5, 0.75])\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Hopkin's Statistic for Determining Clusterability\n",
    "Calculate 5 Hopkin's statistics for this dataset. Do your results suggest that this dataset is clusterable? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.to_numpy()\n",
    "hopkins_values = [hopkins_stat(pd.DataFrame(X)) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the results\n",
    "print(\"Hopkin's Statistic Values:\", hopkins_values)\n",
    "print(\"Mean Hopkin's Statistic:\", np.mean(hopkins_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation and Conclusion\n",
    "mean_hopkins = np.mean(hopkins_values)\n",
    "if mean_hopkins > 0.75:\n",
    "    print(\"The dataset is highly clusterable (Hopkin's statistic > 0.75).\")\n",
    "elif 0.5 <= mean_hopkins <= 0.75:\n",
    "    print(\"The dataset has moderate clusterability (0.5 <= Hopkin's statistic <= 0.75).\")\n",
    "else:\n",
    "    print(\"The dataset is not clusterable (Hopkin's statistic < 0.5).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopkin's Statistic < 0.5 indicates that the dataset is randomly distributed, lacking natural structure or dense regions necessary for meaningful clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.  k-Means\n",
    "\n",
    "Cluster this dataset into two clusters using k-means (and a random state of 100). Then, plot this two dimensional dataset again, color-coding the points by your resulting k-means cluster labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=100, n_init=10)\n",
    "labels = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the clustered data\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', s=50, alpha=0.7)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='red', marker='X', label='Centroids')\n",
    "plt.title(\"k-Means Clustering (k=2)\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6. Clustering Assessment\n",
    "\n",
    "Did k-means accurately identify the clusters in the dataset? If not, explain why.\n",
    "\n",
    "**Hint: Try plotting the dataset with an x-axis lower bound of -300 and an upper bound of 300, and a y-axis lower bound of -300 and an upper bound of 300.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', s=50, alpha=0.7)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='red', marker='X', label='Centroids')\n",
    "plt.xlim(-300, 300)\n",
    "plt.ylim(-300, 300)\n",
    "plt.title(\"Clustering Assessment with Axis Bounds\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**k-Means failed to identify meaningful clusters** because the dataset lacks inherent clusterability, as indicated by the Hopkin's statistic (<0.5).\n",
    "\n",
    "The clusters formed are artificial and based on the algorithm's assumptions of spherical clusters, which do not align with the dataset's random distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### <u>Tutorial</u>: Variable Z-Score Scaling\n",
    "\n",
    "We can scale the numerical attributes in each column of a dataframe by using the **StandardScaler()** function from the the **sklearn.preprocessing** package, followed by the **.fit_transform()** function.\n",
    "\n",
    "Using the default **StandardScaler()** parameters, we standardize the variables by removing the mean and scaling to unit variance. Or in other words, we transform each observation $x$ in a given column to $z=\\frac{x-\\mbox{mean of column}}{\\mbox{standard deviation of column}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tmp=pd.DataFrame({'col1':[100,109,99,97], 'col2': [1,6,3,8]})\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaled_array=StandardScaler().fit_transform(tmp)\n",
    "scaled_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the **StandardScaler().fit_transform()** is a numpy array. Let's put this scaled dataset back into dataframe form, using the same column names from the original tmp dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_scaled=pd.DataFrame(scaled_array, columns=tmp.columns)\n",
    "tmp_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### 2. Scaled Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Scale the dataset\n",
    "\n",
    "Next, with our dataframe from 1.1, create a new dataframe that has standardized the variables by removing the mean and scaling to unit variance.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_array = scaler.fit_transform(df)  # Standardize dataset\n",
    "\n",
    "df_scaled = pd.DataFrame(scaled_array, columns=df.columns)\n",
    "\n",
    "print(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Initial Plotting \n",
    "Plot this **scaled** dataframe in a scatterplot. Just by using this scatterplot, do you think that this scaled dataset is clusterable?\n",
    "\n",
    "**Hint: In this problem, don't modify the upper or lower bound limits of the plot window.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of the scaled dataset\n",
    "plt.scatter(df_scaled.iloc[:, 0], df_scaled.iloc[:, 1], alpha=0.6)\n",
    "plt.title(\"Scatter Plot of Scaled Dataset\")\n",
    "plt.xlabel(\"Feature 1 (Scaled)\")\n",
    "plt.ylabel(\"Feature 2 (Scaled)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.  Describing the Numerical Variales\n",
    "\n",
    "For each numerical variable in the **scaled** dataframe, show the mean, standard deviation, minimum, Q1, median, Q3, and maxium value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.describe(percentiles=[0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.Hopkin's Statistic for Determining Clusterability\n",
    "Calculate 5 Hopkin's statistics for this **scaled** dataset. Do your results suggest that this **scaled** dataset is more likely to be clusterable than the **unscaled** dataset?  Explain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hopkins_values_scaled = [hopkins_stat(X_scaled) for _ in range(5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize results\n",
    "print(\"Hopkin's Statistic Values (Scaled):\", hopkins_values_scaled)\n",
    "print(\"Mean Hopkin's Statistic (Scaled):\", np.mean(hopkins_values_scaled))\n",
    "\n",
    "# Comparison Conclusion\n",
    "if np.mean(hopkins_values_scaled) > 0.75:\n",
    "    print(\"The scaled dataset is highly clusterable.\")\n",
    "elif 0.5 <= np.mean(hopkins_values_scaled) <= 0.75:\n",
    "    print(\"The scaled dataset has moderate clusterability.\")\n",
    "else:\n",
    "    print(\"The scaled dataset is not clusterable.\")\n",
    "\n",
    "# Compare with unscaled dataset\n",
    "print(\"Comparison: If the Hopkin's statistic for the scaled dataset is significantly higher than the unscaled dataset, scaling has improved clusterability.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5. Assumptions of the Hopkin's Statistic\n",
    "\n",
    "If we had shifted all of the points in just the lower cloud of observations in this scaled dataset to the right by 5, would we expect the Hopkin's statistics and it's interpretations to change? If so, in what way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6. k-Means\n",
    "\n",
    "Cluster this **scaled** dataset into two clusters using k-means (and a random state of 100). Then, plot this **scaled** two dimensional dataset again, color-coding the points by your resulting k-means cluster labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## <u>Case Study 2</u>: Wheat Seed Analysis\n",
    "\n",
    "Suppose that you are biologist working for an agricultural company. Specifically, you would like to learn more about some of the biological properties of three types of wheat seeds: Kama wheat seeds, Canadian wheat seeds, and Rosa wheat seeds.\n",
    "\n",
    "The attached seeds.csv contains seven numerical attributes for 70 Kama seeds, 70 Canadian seeds, and 70 Rosa seeds. In this analysis we would like to answer the following research questions.\n",
    "\n",
    "### <u>Research Questions</u>:\n",
    "\n",
    "1. Does there exist a clustering structure in this dataset?\n",
    "2. Which clustering algorithm (k-means vs. k-medoids) will yield a clustering with the most amount of cohesion and separation?\n",
    "3. If our goal is to yield clusterings with high cohesion and separation, what number of clusters should we ask for in the k-means and k-medoids algorithms?\n",
    "4. How similar are our k-means and k-medoids clusterings results to the seed class labels (ie. Kama, Canadian, and Rosa)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Reading and Preprocessing\n",
    "\n",
    "#### 1.1. Reading dataset\n",
    "\n",
    "Read the `seeds_modified.csv` dataset into a dataframe. You can assume that this dataset has no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.  Summary Statistics\n",
    "\n",
    "For each numerical variable in the dataframe, show the mean, standard deviation, minimum, Q1, median, Q3, and maxium value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.  Attribute Influence in k-Means\n",
    "\n",
    "If we were to apply k-means to this dataset, do you think that certain numerical variables in this dataset that are more likely to dominate the results of k-means more than others? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.  Scale the dataset\n",
    "\n",
    "Create a copy of your seeds dataframe that is comprised of just the numerical variables. Then create a new dataframe (or overwrite this dataframe) that has scaled the numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Basic Descriptive Analytics\n",
    "\n",
    "Before performing cluster analysis, we would like to explore this dataset first by using some more basic descriptive analytics techniques.\n",
    "\n",
    "#### 2.1. Attribute Relationships\n",
    "\n",
    "First, for each pair of the 7 numerical attributes in this dataset, plot a scatterplot. Color-code the observations in each of these scatterplots by the seed class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Outliers\n",
    "\n",
    "Do you think that this dataset has any outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Algorithm Selection\n",
    "\n",
    "If this dataset were to have outliers, would k-means or k-medoids be a more appropriate algorithm to use to cluster the data? Assume that you did not want to have clusters with a very small number of observations in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Clusterability\n",
    "\n",
    "Generate 5 Hopkin's statistics for this **scaled** dataset and comment on whether or not these Hopkin's statistics suggest that the dataset is clusterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Parameter Selection for k-Means\n",
    "\n",
    "We would like to use k-means to cluster this **scaled** dataset. Let's use the average silhouette score to help us select the ideal number of clusters to ask k-means for.\n",
    "\n",
    "#### 4.1. Average Silhouette Score Plot\n",
    "\n",
    "Using k-means and clusterings with k=2,3,...,10 clusters, create an average silhoutte score plot for this **scaled** dataset (creating 3 k-means clusterings for each k value).\n",
    "\n",
    "Each of your 3 runs of the k-means clustering algorithm (for a given k) should use the random states `100,101,102`\n",
    "\n",
    "Code Hint: \n",
    "\n",
    "`for rs in [100,101,102]:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Interpretation\n",
    "\n",
    "What number of clusters does the plot above suggest will yield the clustering with the best cohesion and separation, when using k-means?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. k-means Cluster Analysis\n",
    "\n",
    "Cluster your scaled seeds dataset into the number of k clusters that you selected above using k-means and a random state of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Post-Cluster Analysis with k-means\n",
    "\n",
    "#### 6.1. Cluster labels and pre-assigned class labels comparision\n",
    "\n",
    "Calculate the adjusted rand score between the k-means clustering that you created in 5 and the seed class labels. Then interpret this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.  Calculate the average silhouette score of the clustering you created in 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.  Create a silhouette plot for the **scaled** dataset clustering that you created in 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.  Which cluster in the dataset has the worst cohesion and separation? Which cluster has the best? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5. k-Means and the Scatterplots\n",
    "\n",
    "For each pair of the 7 numerical attributes in this dataset, plot a scatterplot. Color-code the observations in each of these scatterplots by the `k-means cluster labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Parameter Selection for k-Medoids\n",
    "\n",
    "We would also like to use k-medoids to cluster this **scaled** dataset. Let's use the average silhouette score to help us select the ideal number of clusters to ask k-medoids for.\n",
    "\n",
    "#### 7.1. Average Silhouette Score Plot\n",
    "\n",
    "Using k-medoids and clusterings with k=2,3,...,10 clusters, create an average silhoutte score plot for this **scaled** dataset (creating `3` k-medoids clusterings for each k value).\n",
    "\n",
    "Each of your 3 runs of the k-medoids clustering algorithm (for a given k) should use the random states `100,101,102`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2. Interpretation\n",
    "\n",
    "What number of clusters does the plot above suggest will yield the best clustering, when using k-medoids?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. k-Medoids Cluster Analysis\n",
    "\n",
    "Cluster your scaled seeds dataset into the number of k clusters that you selected above using k-medoids and a random state of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Post-Cluster Analysis with k-means\n",
    "\n",
    "#### 9.1. Cluster labels and pre-assigned class labels comparision\n",
    "\n",
    "Calculate the adjusted rand score between the k-medoids clustering that you created in 8 and the seed class labels. Then interpret this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.  Calculate the average silhouette score of the clustering you created in 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3.  Create a silhouette plot for the clustering that you created in 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.4.  Which cluster in the clustering had the objects with the worst cluster cohesion? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.5. k-Medoids and the Scatterplots\n",
    "\n",
    "For each pair of the 7 numerical attributes in this dataset, plot a scatterplot. Color-code the observations in each of these scatterplots by the `k-medoids cluster labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Clustering Comparison\n",
    "\n",
    "Finally, let's compare the two clusterings that were created by the k-means clustering algorithm and the k-medoids clustering algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1. Association with the Seed Class Labels\n",
    "\n",
    "1. Which clustering had a stronger association with (ie. similarity to) the set of seed class labels? Explain.\n",
    "2. Does this suggest that this clustering algorithm performed better with respect to our unsupervised learning research goal? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2. Cohesion and Separation and Desired Type of Clustering Results\n",
    "\n",
    "1. Did the k-means clustering or the k-medoids clustering have stronger cohesion and separation? Explain.\n",
    "2. Suppose that the researcher conducting this analysis did not want any clusters with a very small number of observations in them, and instead preferred more balanced clusters. Which clustering would you choose in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
